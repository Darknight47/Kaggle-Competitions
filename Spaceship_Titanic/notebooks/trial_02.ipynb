{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf08fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc6039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"../dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f49b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def preprocess(df):\n",
    "    df[\"Group\"] = df[\"PassengerId\"].str.split(\"_\").str[0]\n",
    "    df[[\"Cabin_Deck\", \"Cabin_Num\", \"Cabin_Side\"]] = df[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "    df[\"Cabin_Num\"] = pd.to_numeric(df[\"Cabin_Num\"], errors=\"coerce\")\n",
    "    df['LastName'] = df['Name'].str.split(\" \").str[1]\n",
    "    return df\n",
    "\n",
    "def fill_from_group(df, col):\n",
    "    grp_mode = df.groupby(\"Group\")[col].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "    df[col] = df.apply(lambda r: grp_mode[r[\"Group\"]] if pd.isna(r[col]) else r[col], axis=1)\n",
    "    return df\n",
    "\n",
    "def impute_rule_based(df):\n",
    "    # ---- HomePlanet rules ----\n",
    "    missing = df[\"HomePlanet\"].isna()\n",
    "    cond = missing & df[\"VIP\"].eq(True)\n",
    "    df.loc[cond, \"HomePlanet\"] = \"Europa\"   # Europa VIP dominates Mars VIP\n",
    "\n",
    "    cond = missing & df[\"Cabin_Deck\"].isin([\"A\", \"B\", \"C\"])\n",
    "    df.loc[cond, \"HomePlanet\"] = \"Europa\"\n",
    "\n",
    "    cond = missing & df[\"Cabin_Deck\"].isin([\"F\", \"G\"])\n",
    "    df.loc[cond, \"HomePlanet\"] = \"Earth\"\n",
    "\n",
    "    cond = missing & df[\"Cabin_Deck\"].isin([\"D\", \"E\"])\n",
    "    df.loc[cond, \"HomePlanet\"] = \"Mars\"\n",
    "\n",
    "    cond = missing & df[\"Destination\"].eq(\"55 Cancri e\")\n",
    "    df.loc[cond, \"HomePlanet\"] = \"Europa\"\n",
    "\n",
    "    cond = missing & df[\"Destination\"].eq(\"PSO J318.5-22\")\n",
    "    df.loc[cond, \"HomePlanet\"] = \"Earth\"\n",
    "\n",
    "    cond = df[\"HomePlanet\"].isna()\n",
    "    df.loc[cond, \"HomePlanet\"] = \"Earth\"  # global mode\n",
    "\n",
    "\n",
    "    # ---- CryoSleep rules ----\n",
    "    amenities = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "    total_spending = df[amenities].sum(axis=1)\n",
    "\n",
    "    cond = df[\"CryoSleep\"].isna() & (total_spending > 0)\n",
    "    df.loc[cond, \"CryoSleep\"] = False\n",
    "\n",
    "    cond = df[\"CryoSleep\"].isna() & (total_spending == 0)\n",
    "    df.loc[cond, \"CryoSleep\"] = True\n",
    "\n",
    "    cond = df[\"CryoSleep\"].isna() & df[\"Cabin_Deck\"].isin([\"B\", \"G\"])\n",
    "    df.loc[cond, \"CryoSleep\"] = True\n",
    "\n",
    "    cond = df[\"CryoSleep\"].isna() & df[\"Cabin_Deck\"].isin([\"E\", \"F\", \"T\"])\n",
    "    df.loc[cond, \"CryoSleep\"] = False\n",
    "\n",
    "\n",
    "    # ---- Destination rules ----\n",
    "    cond = df[\"Destination\"].isna() & df[\"HomePlanet\"].eq(\"Europa\")\n",
    "    df.loc[cond, \"Destination\"] = \"55 Cancri e\"\n",
    "\n",
    "    cond = df[\"Destination\"].isna() & df[\"HomePlanet\"].eq(\"Mars\")\n",
    "    df.loc[cond, \"Destination\"] = \"TRAPPIST-1e\"\n",
    "\n",
    "    cond = df[\"Destination\"].isna() & df[\"HomePlanet\"].eq(\"Earth\")\n",
    "    df.loc[cond, \"Destination\"] = \"TRAPPIST-1e\"\n",
    "\n",
    "    cond = df[\"Destination\"].isna()\n",
    "    df.loc[cond, \"Destination\"] = \"TRAPPIST-1e\"  # global mode\n",
    "\n",
    "\n",
    "    # ---- VIP rules ----\n",
    "    cond = df[\"VIP\"].isna() & (total_spending > total_spending.quantile(0.75))\n",
    "    df.loc[cond, \"VIP\"] = True\n",
    "    #mple, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, t\n",
    "    df['VIP'] = df['VIP'].fillna(False)\n",
    "\n",
    "\n",
    "    # ---- Cabin Deck/Side/Num ----\n",
    "    df[\"Cabin_Deck\"] =  df[\"Cabin_Deck\"].fillna(df[\"Cabin_Deck\"].mode()[0])\n",
    "    df[\"Cabin_Side\"] = df[\"Cabin_Side\"].fillna(df[\"Cabin_Side\"].mode()[0])\n",
    "\n",
    "    # Cabin_Num → group median → deck median → global\n",
    "    grp_med = df.groupby(\"Group\")[\"Cabin_Num\"].transform(\"median\")\n",
    "    df[\"Cabin_Num\"] = df[\"Cabin_Num\"].fillna(grp_med)\n",
    "    deck_med = df.groupby(\"Cabin_Deck\")[\"Cabin_Num\"].transform(\"median\")\n",
    "    df[\"Cabin_Num\"] = df[\"Cabin_Num\"].fillna(deck_med)\n",
    "    df[\"Cabin_Num\"] = df[\"Cabin_Num\"].fillna(df[\"Cabin_Num\"].median())\n",
    "\n",
    "    return df\n",
    "\n",
    "def ml_impute_age_and_spending(df):\n",
    "    amenities = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "\n",
    "    # Set spending = 0 for CryoSleep == True\n",
    "    for col in amenities:\n",
    "        df.loc[df[\"CryoSleep\"] == True, col] = df.loc[df[\"CryoSleep\"] == True, col].fillna(0)\n",
    "\n",
    "    # Train ML model for Age\n",
    "    features = [\"HomePlanet\", \"Destination\", \"VIP\", \"CryoSleep\", \"Cabin_Deck\", \"Cabin_Num\"]\n",
    "    df_ml = pd.get_dummies(df[features], drop_first=True)\n",
    "\n",
    "    train_mask = df[\"Age\"].notna()\n",
    "    model = RandomForestRegressor(n_estimators=250, random_state=42)\n",
    "    model.fit(df_ml[train_mask], df.loc[train_mask, \"Age\"])\n",
    "    pred = model.predict(df_ml[df[\"Age\"].isna()])\n",
    "    df.loc[df[\"Age\"].isna(), \"Age\"] = pred\n",
    "\n",
    "    # Final fill for spending values (group median > 0)\n",
    "    grp_med = df.groupby(\"Group\")[amenities].transform(\"median\")\n",
    "    for col in amenities:\n",
    "        df[col] = df[col].fillna(grp_med[col])\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3271c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_pipeline(df):\n",
    "    df = preprocess(df)\n",
    "\n",
    "    # Group-based first\n",
    "    for col in [\"HomePlanet\", \"Destination\", \"Cabin_Deck\", \"Cabin_Side\", \"CryoSleep\", \"VIP\", \"LastName\"]:\n",
    "        df = fill_from_group(df, col)\n",
    "\n",
    "    df = impute_rule_based(df)\n",
    "    df = ml_impute_age_and_spending(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bd228",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed = impute_pipeline(train_df.copy())\n",
    "test_processed = impute_pipeline(test_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edcf1a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_engineered_features(df):\n",
    "    # ---------- 1. Total / Category Spending ----------\n",
    "    df[\"TotalSpending\"] = df[[\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]].sum(axis=1)\n",
    "\n",
    "    df[\"LuxurySpending\"] = df[[\"FoodCourt\", \"ShoppingMall\", \"Spa\"]].sum(axis=1)\n",
    "    df[\"EntertainmentSpending\"] = df[\"VRDeck\"]\n",
    "\n",
    "    # Spending flags\n",
    "    df[\"SpentNothing\"] = (df[\"TotalSpending\"] == 0).astype(int)\n",
    "    df[\"LuxuryUser\"] = (df[\"LuxurySpending\"] > 0).astype(int)\n",
    "\n",
    "    # ---------- 2. Group Statistics ----------\n",
    "    # Group size\n",
    "    group_size = df.groupby(\"Group\")[\"PassengerId\"].transform(\"count\")\n",
    "    df[\"GroupSize\"] = group_size\n",
    "\n",
    "    # Group high spender trait\n",
    "    group_max_spend = df.groupby(\"Group\")[\"TotalSpending\"].transform(\"max\")\n",
    "    df[\"GroupMaxSpending\"] = group_max_spend\n",
    "\n",
    "    # CryoSleep ratio in group\n",
    "    df[\"GroupCryoRatio\"] = df.groupby(\"Group\")[\"CryoSleep\"].transform(\"mean\")\n",
    "\n",
    "    # Spending difference vs group median\n",
    "    df[\"GroupMedianSpending\"] = df.groupby(\"Group\")[\"TotalSpending\"].transform(\"median\")\n",
    "    df[\"SpendingDiff\"] = df[\"TotalSpending\"] - df[\"GroupMedianSpending\"]\n",
    "\n",
    "    # ---------- 3. Deck rank / cabin location ----------\n",
    "    deck_order = {\"A\": 7, \"B\": 6, \"C\": 5, \"D\": 4, \"E\": 3, \"F\": 2, \"G\": 1, \"T\": 0}\n",
    "    df[\"DeckRank\"] = df[\"Cabin_Deck\"].map(deck_order)\n",
    "\n",
    "    # Forward (low Cabin_Num) vs Rear (high Cabin_Num)\n",
    "    median_cabin_num = df[\"Cabin_Num\"].median()\n",
    "    df[\"IsRearCabin\"] = (df[\"Cabin_Num\"] >= median_cabin_num).astype(int)\n",
    "    df[\"IsPort\"] = (df[\"Cabin_Side\"] == \"P\").astype(int)\n",
    "    df[\"IsStar\"] = (df[\"Cabin_Side\"] == \"S\").astype(int)\n",
    "\n",
    "    # ---------- 4. Age categories ----------\n",
    "    df[\"Child\"] = (df[\"Age\"] < 12).astype(int)\n",
    "    df[\"Teen\"] = ((df[\"Age\"] >= 12) & (df[\"Age\"] < 20)).astype(int)\n",
    "    df[\"Adult\"] = ((df[\"Age\"] >= 20) & (df[\"Age\"] < 60)).astype(int)\n",
    "    df[\"Senior\"] = (df[\"Age\"] >= 60).astype(int)\n",
    "\n",
    "\n",
    "    # ---------- 5. CryoSleep interactions ----------\n",
    "    df[\"Awake\"] = (~df[\"CryoSleep\"]).astype(int)\n",
    "    df[\"SpentNothingAwake\"] = ((df[\"TotalSpending\"] == 0) & (df[\"CryoSleep\"] == False)).astype(int)\n",
    "    df[\"Awake_Luxury\"] = ((df[\"LuxurySpending\"] > 0) & (df[\"CryoSleep\"] == False)).astype(int)\n",
    "\n",
    "    # ---------- 6. Cross-feature: Deck × Destination ----------\n",
    "    df[\"Deck_Destination\"] = df[\"Cabin_Deck\"] + \"_\" + df[\"Destination\"]\n",
    "\n",
    "\n",
    "    # ---------- 7. Group categorical support features ----------\n",
    "    group_hp = df.groupby(\"Group\")[\"HomePlanet\"].agg(lambda x: x.mode().iloc[0])\n",
    "    df[\"GroupHomePlanet\"] = df[\"Group\"].map(group_hp)\n",
    "\n",
    "    group_dest = df.groupby(\"Group\")[\"Destination\"].agg(lambda x: x.mode().iloc[0])\n",
    "    df[\"GroupDestination\"] = df[\"Group\"].map(group_dest)\n",
    "\n",
    "    group_vip = df.groupby(\"Group\")[\"VIP\"].transform(\"max\")\n",
    "    df[\"GroupHasVIP\"] = group_vip.astype(int)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0932530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fe = add_engineered_features(train_processed.copy())\n",
    "test_fe = add_engineered_features(test_processed.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f39557da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_fe['Transported'].astype(int)   # Convert True/False to 1/0\n",
    "X_train_cat = train_fe.drop(columns=['Transported', 'PassengerId', 'Name', 'LastName', 'Deck_Destination'])\n",
    "X_test_cat = test_fe.drop(columns=['PassengerId', 'Name', 'LastName', 'Deck_Destination'])\n",
    "\n",
    "# Define categorical columns explicitly\n",
    "categorical_cols = [\n",
    "    'HomePlanet',\n",
    "    'CryoSleep',\n",
    "    'Cabin',\n",
    "    'Destination',       # <-- include this!\n",
    "    'VIP',\n",
    "    'Cabin_Deck',\n",
    "    'Cabin_Side',\n",
    "    'GroupHomePlanet',\n",
    "    'GroupDestination'\n",
    "]\n",
    "\n",
    "# Cast to string\n",
    "for col in categorical_cols:\n",
    "    if col in X_train_cat.columns:\n",
    "        X_train_cat[col] = X_train_cat[col].astype(str)\n",
    "        X_test_cat[col] = X_test_cat[col].astype(str)\n",
    "\n",
    "# Get indices for CatBoost\n",
    "cat_feature_indices = [\n",
    "    X_train_cat.columns.get_loc(col)\n",
    "    for col in categorical_cols\n",
    "    if col in X_train_cat.columns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6299bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a753250",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    'iterations': 3000,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 7,\n",
    "    'l2_leaf_reg': 5,\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'Accuracy',\n",
    "    'random_seed': 42,\n",
    "    'verbose': False,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'task_type': 'CPU',          # Switch to 'GPU' if available\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    #'subsample': 0.8,\n",
    "    'rsm': 0.9,\n",
    "    'border_count': 128,\n",
    "    'grow_policy': 'SymmetricTree'\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "catboost_cv_scores = []\n",
    "catboost_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "31565349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical indices: [0, 1, 2, 3, 5, 12, 14, 36, 37]\n",
      "Categorical columns: ['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', 'Cabin_Deck', 'Cabin_Side', 'GroupHomePlanet', 'GroupDestination']\n"
     ]
    }
   ],
   "source": [
    "print(\"Categorical indices:\", cat_feature_indices)\n",
    "print(\"Categorical columns:\", [X_train_cat.columns[i] for i in cat_feature_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6a65856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.8125 (Best iteration: 161)\n",
      "Fold 2: Accuracy = 0.8045 (Best iteration: 264)\n",
      "Fold 3: Accuracy = 0.8177 (Best iteration: 218)\n",
      "Fold 4: Accuracy = 0.8176 (Best iteration: 319)\n",
      "Fold 5: Accuracy = 0.7940 (Best iteration: 66)\n",
      "Mean CV Accuracy: 0.8093\n"
     ]
    }
   ],
   "source": [
    "for fold_num, (train_idx, val_idx) in enumerate(skf.split(X_train_cat, y), 1):\n",
    "    X_tr, X_val = X_train_cat.iloc[train_idx], X_train_cat.iloc[val_idx]\n",
    "    y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    train_pool = Pool(X_tr, y_tr, cat_features=cat_feature_indices)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=cat_feature_indices)\n",
    "\n",
    "    model = CatBoostClassifier(**catboost_params)\n",
    "    model.fit(train_pool, eval_set=val_pool, verbose=False)\n",
    "\n",
    "    y_pred = model.predict(X_val).flatten()\n",
    "    fold_score = accuracy_score(y_val, y_pred)\n",
    "    catboost_cv_scores.append(fold_score)\n",
    "    catboost_models.append(model)\n",
    "\n",
    "    print(f\"Fold {fold_num}: Accuracy = {fold_score:.4f} (Best iteration: {model.best_iteration_})\")\n",
    "\n",
    "print(f\"Mean CV Accuracy: {np.mean(catboost_cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c2a45b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7579662\ttotal: 25.1ms\tremaining: 1m 15s\n",
      "100:\tlearn: 0.8154837\ttotal: 2.66s\tremaining: 1m 16s\n",
      "200:\tlearn: 0.8273323\ttotal: 5.19s\tremaining: 1m 12s\n",
      "300:\tlearn: 0.8424019\ttotal: 7.82s\tremaining: 1m 10s\n",
      "400:\tlearn: 0.8522949\ttotal: 10.5s\tremaining: 1m 8s\n",
      "500:\tlearn: 0.8662142\ttotal: 13.1s\tremaining: 1m 5s\n",
      "600:\tlearn: 0.8763373\ttotal: 16.1s\tremaining: 1m 4s\n",
      "700:\tlearn: 0.8849649\ttotal: 18.9s\tremaining: 1m 2s\n",
      "800:\tlearn: 0.8942828\ttotal: 21.5s\tremaining: 59s\n",
      "900:\tlearn: 0.9016450\ttotal: 24.2s\tremaining: 56.3s\n",
      "1000:\tlearn: 0.9078569\ttotal: 26.8s\tremaining: 53.6s\n",
      "1100:\tlearn: 0.9140688\ttotal: 29.5s\tremaining: 50.9s\n",
      "1200:\tlearn: 0.9203957\ttotal: 32.1s\tremaining: 48.1s\n",
      "1300:\tlearn: 0.9258024\ttotal: 34.7s\tremaining: 45.3s\n",
      "1400:\tlearn: 0.9302887\ttotal: 37.4s\tremaining: 42.6s\n",
      "1500:\tlearn: 0.9362706\ttotal: 40s\tremaining: 39.9s\n",
      "1600:\tlearn: 0.9414471\ttotal: 42.6s\tremaining: 37.2s\n",
      "1700:\tlearn: 0.9447832\ttotal: 45.2s\tremaining: 34.5s\n",
      "1800:\tlearn: 0.9488094\ttotal: 47.8s\tremaining: 31.8s\n",
      "1900:\tlearn: 0.9521454\ttotal: 50.4s\tremaining: 29.1s\n",
      "2000:\tlearn: 0.9560566\ttotal: 52.9s\tremaining: 26.4s\n",
      "2100:\tlearn: 0.9587024\ttotal: 55.5s\tremaining: 23.7s\n",
      "2200:\tlearn: 0.9612332\ttotal: 58s\tremaining: 21s\n",
      "2300:\tlearn: 0.9633038\ttotal: 1m\tremaining: 18.5s\n",
      "2400:\tlearn: 0.9657195\ttotal: 1m 3s\tremaining: 15.9s\n",
      "2500:\tlearn: 0.9672150\ttotal: 1m 6s\tremaining: 13.2s\n",
      "2600:\tlearn: 0.9688255\ttotal: 1m 8s\tremaining: 10.5s\n",
      "2700:\tlearn: 0.9707811\ttotal: 1m 11s\tremaining: 7.88s\n",
      "2800:\tlearn: 0.9725066\ttotal: 1m 13s\tremaining: 5.24s\n",
      "2900:\tlearn: 0.9734269\ttotal: 1m 16s\tremaining: 2.61s\n",
      "2999:\tlearn: 0.9760727\ttotal: 1m 18s\tremaining: 0us\n",
      "Train Accuracy: 0.9144\n"
     ]
    }
   ],
   "source": [
    "train_pool_full = Pool(X_train_cat, y, cat_features=cat_feature_indices)\n",
    "test_pool_cat = Pool(X_test_cat, cat_features=cat_feature_indices)\n",
    "\n",
    "catboost_final_model = CatBoostClassifier(**catboost_params)\n",
    "catboost_final_model.fit(train_pool_full, verbose=100)\n",
    "\n",
    "# Training accuracy\n",
    "y_train_pred_cat = catboost_final_model.predict(X_train_cat).flatten()\n",
    "catboost_train_accuracy = accuracy_score(y, y_train_pred_cat)\n",
    "print(f\"Train Accuracy: {catboost_train_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5d211188",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_cat = catboost_final_model.predict(X_test_cat).flatten()\n",
    "y_test_pred_cat_bool = y_test_pred_cat.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2809070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_fe['PassengerId'],\n",
    "    'Transported': y_test_pred_cat_bool\n",
    "})\n",
    "submission.to_csv(\"submission_catboost_03.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
