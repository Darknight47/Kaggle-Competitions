{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb16aa6",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc2fde27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ceb1b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1070ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000, 26)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2251cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnosed_diabetes\n",
      "1.0    436307\n",
      "0.0    263693\n",
      "Name: count, dtype: int64\n",
      "diagnosed_diabetes\n",
      "1.0    0.623296\n",
      "0.0    0.376704\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['diagnosed_diabetes'].value_counts())\n",
    "print(train_df['diagnosed_diabetes'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "917fd8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'ethnicity', 'education_level', 'income_level',\n",
       "       'smoking_status', 'employment_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = train_df.select_dtypes(include='object').columns\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2fbadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "age - min/max/median:  19 89 50.0\n",
      "\n",
      "bmi - min/max/median:  15.1 38.4 25.9\n",
      "\n",
      "systolic_bp - min/max/median:  91 163 116.0\n",
      "\n",
      "diastolic_bp - min/max/median:  51 104 75.0\n",
      "\n",
      "sleep_hours_per_day - min/max/median:  3.1 9.9 7.0\n",
      "\n",
      "alcohol_consumption_per_week - min/max/median:  1 9 2.0\n"
     ]
    }
   ],
   "source": [
    "for c in ['age','bmi','systolic_bp','diastolic_bp','sleep_hours_per_day','alcohol_consumption_per_week']:\n",
    "    if c in train_df.columns:\n",
    "        print(f\"\\n{c} - min/max/median: \", train_df[c].min(), train_df[c].max(), train_df[c].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94be99b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate ids in train: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDuplicate ids in train:\", train_df['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d89621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Working copies (safe practice)\n",
    "train = train_df.copy()\n",
    "\n",
    "# 2. Separate target variable\n",
    "y = train[\"diagnosed_diabetes\"]\n",
    "X = train.drop(columns=[\"diagnosed_diabetes\", \"id\"])\n",
    "test = test_df.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ee0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_cols = ['gender', 'ethnicity', 'employment_status']\n",
    "ordinal_cols = ['education_level', 'income_level', 'smoking_status']\n",
    "\n",
    "# Define the order for ordinal features\n",
    "education_order = [\"No formal\", \"Highschool\", \"Graduate\", \"Postgraduate\"]  \n",
    "income_order    = [\"Low\", \"Lower-Middle\", \"Middle\", \"Upper-Middle\", \"High\"]\n",
    "smoking_order   = [\"Never\", \"Current\", \"Former\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "add7f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal -> OneHot (binary indicators). Creates a new column for each category.\n",
    "nominal_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "# Ordinal -> integer encoding with defined order. Assigns integer values based on order.\n",
    "ordinal_transformer = OrdinalEncoder(\n",
    "    categories=[education_order, income_order, smoking_order],\n",
    "    dtype=int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ef35458",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"nominal\", nominal_transformer, nominal_cols),\n",
    "        (\"ordinal\", ordinal_transformer, ordinal_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\" # keeps continuous columns as is. Numeric columns (passthrough) → converted to NumPy array\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7c219d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prepared = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "029be08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y, # preserving target class distribution in train and val sets\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a714b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"rf\", RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2, # A node must have at least 2 samples to split.\n",
    "        min_samples_leaf=1,\n",
    "        max_features=\"sqrt\", # Standard for classification; reduces correlation between trees.\n",
    "        bootstrap=True, # Sample with replacement\n",
    "        class_weight=\"balanced\", # Helps handle class imbalance, improves sensitivity to minority class.\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7056d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7a8e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = rf_pipeline.predict_proba(X_val)[:, 1] \n",
    "# returns probability estimates for each class.\n",
    "# We take column [:, 1] → probability of positive class (diabetes).\n",
    "# Random Forest probability = average of leaf probabilities from all trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ea38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC-AUC (a baseline performance): 0.6976153313173052\n"
     ]
    }
   ],
   "source": [
    "val_auc = roc_auc_score(y_val, val_preds)  # A single train/validation split can be unstable\n",
    "print(\"Validation ROC-AUC (a baseline performance):\", val_auc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4229197c",
   "metadata": {},
   "source": [
    "A single train/validation split can be unstable\n",
    "\n",
    "CV reduces randomness\n",
    "\n",
    "CV helps detect overfitting\n",
    "\n",
    "CV helps find the best hyperparameters more reliably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec228a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'blank' RandomForestClassifier, hyperparameters will be supplied by RandomizedSearchCV\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ee84b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each value is a *list of possible values* that the search will sample from.\n",
    "# RandomizedSearchCV will randomly choose combinations from this space.\n",
    "parameters = {\n",
    "    \"n_estimators\": [400, 600, 800, 1000], # Number of trees in the forest. More trees = Lower variance, but higher computational cost.\n",
    "    \"max_depth\": [10, 20, 30, 40, 50], # Maximum depth of each tree. Limits how much the tree can grow, avoids overfitting!\n",
    "    \"min_samples_split\": [2, 5, 10, 20], # Minimum number of samples required to split a node. Higher values = more conservative trees -> Less overfitting.\n",
    "    \"min_samples_leaf\": [1, 2, 4, 8], # Minimum number of samples needed at a leaf node. Higher values smooth the model and reduce noise fitting.\n",
    "    \"max_features\": ['sqrt', 'log2', None], # Number of features considered when deciding a split. \"sqrt\" → faster, adds randomness → helps prevent overfitting. \"log2\" → even fewer features.\n",
    "    \"bootstrap\": [True, False] # Whether bootstrap sampling is used for trees. Usually bootstrap=True works best; False trains on all rows.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48875d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedKFold ensures each fold has the same class proportion as the original dataset → critical for imbalanced data.\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=3,  # 3-fold CV → train on 80%, validate on 20% each fold\n",
    "    shuffle=True,  # Shuffles data before splitting → reduces variance\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV:\n",
    "# - Randomly samples N hyperparameter combinations\n",
    "# - For each combination, performs cross-validation\n",
    "# - Computes mean validation ROC-AUC for each combination\n",
    "# - Returns the best parameters and best score\n",
    "\n",
    "# Why \"randomized\" instead of full grid search?\n",
    "# - Much faster\n",
    "# - Often finds equally good or better solutions\n",
    "# - Allows larger search spaces\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=rf, # The model we want to tune\n",
    "    search_spaces=parameters, # The hyperparameter search space\n",
    "    n_iter=30, # Number of random combinations to try\n",
    "    scoring='roc_auc', # Evaluation metric\n",
    "    n_jobs=1, # Use all CPU cores\n",
    "    cv=cv, # Cross-validation strategy\n",
    "    verbose=2, # Print progress during fitting\n",
    "    random_state=42 # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c073299",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = preprocessor.fit_transform(X)\n",
    "y_train = y\n",
    "\n",
    "sample_size = 150000\n",
    "\n",
    "X_sample = X_train_prepared[:sample_size]\n",
    "y_sample = y_train[:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27baf895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the search object on the FULL TRAINING DATA (X_train, y_train)\n",
    "# Note: we do NOT include validation data here — CV handles the splitting.\n",
    "# This step:\n",
    "# - samples hyperparameters\n",
    "# - trains the model ~30 times (one for each combination)\n",
    "# - each of those uses 5-fold CV → ~150 total model fits\n",
    "# - selects the best combination based on average ROC-AUC\n",
    "bayes_search.fit(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eae471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8236fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna calls this function for each trial (iteration). \n",
    "    It suggests hyperparameters, trains the RF model with CV, \n",
    "    and returns the score to be maximized/minimized.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the search space using Optuna's suggest methods\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1500)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 70)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "\n",
    "    # Create the Random Forest Classifier with the suggested hyperparameters\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        n_jobs=7,          # Use all available cores for speed during training\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Use cross_val_score to evaluate the model\n",
    "    # The scoring here is 'roc_auc' as requested in your previous setup\n",
    "    score = cross_val_score(\n",
    "        model, \n",
    "        X_sample, \n",
    "        y_sample, \n",
    "        cv=3,               # Using cv=3 for faster iterations\n",
    "        scoring='roc_auc', \n",
    "        n_jobs=1           # Parallelize CV fits if possible\n",
    "    ).mean() # Return the average CV score\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaa1ed58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-06 15:55:54,021] A new study created in memory with name: no-name-3a726ac9-b487-4d49-be40-ccfc87918a58\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ca8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_trials is the total number of iterations you want to run (e.g., 30 intelligent rounds)\n",
    "print(\"Starting Optuna optimization...\")\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9539c922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization finished.\n",
      "Best trial value (ROC AUC): 0.7042\n",
      "Best hyperparameters found:\n",
      "{'n_estimators': 729, 'max_depth': 63, 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': None, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOptimization finished.\")\n",
    "print(f\"Best trial value (ROC AUC): {study.best_value:.4f}\")\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c23d29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Working copies (safe practice)\n",
    "train = train_df.copy()\n",
    "\n",
    "# 2. Separate target variable\n",
    "y = train[\"diagnosed_diabetes\"]\n",
    "X = train.drop(columns=[\"diagnosed_diabetes\", \"id\"])\n",
    "test = test_df.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f37dee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = preprocessor.fit_transform(X)\n",
    "X_test_processed = preprocessor.transform(test)\n",
    "y_train = y\n",
    "rf_pipeline_final = Pipeline(steps=[\n",
    "    #(\"preprocessor\", preprocessor),\n",
    "    (\"rf\", RandomForestClassifier(**study.best_params, n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5dad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline_final.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "670ecc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = rf_pipeline_final.predict_proba(X_test_processed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6179d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51423813, 0.62525763, 0.72274039, ..., 0.46561524, 0.57963339,\n",
       "       0.62738994])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "057e0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "rf_submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'diagnosed_diabetes': y_pred\n",
    "})\n",
    "rf_submission.to_csv('rf_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
