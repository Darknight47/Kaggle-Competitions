{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaad5f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd91ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "# -------------------- Prepare features and target \n",
    "target = 'diagnosed_diabetes'\n",
    "features = [col for col in train_df.columns if col not in [target, 'id']]\n",
    "\n",
    "cat_cols = train_df[features].select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    train_df[col] = train_df[col].astype('category')\n",
    "    test_df[col] = test_df[col].astype('category')\n",
    "\n",
    "# -------------- X and y\n",
    "X = train_df[features]\n",
    "y = train_df[target]\n",
    "X_test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb325a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Add these 6 features to both train and test ===\n",
    "train_df['triglycerides_to_hdl'] = train_df['triglycerides'] / train_df['hdl_cholesterol']\n",
    "train_df['non_hdl_cholesterol']  = train_df['cholesterol_total'] - train_df['hdl_cholesterol']\n",
    "train_df['bmi_waist_interaction'] = train_df['bmi'] * train_df['waist_to_hip_ratio']\n",
    "train_df['age_family_interaction'] = train_df['age'] * train_df['family_history_diabetes']\n",
    "train_df['obese'] = (train_df['bmi'] >= 30).astype('category')\n",
    "\n",
    "# Gender-specific thresholds\n",
    "hdl_low = np.where(\n",
    "    train_df['gender'] == 'Male',\n",
    "    (train_df['hdl_cholesterol'] < 40).astype(int),\n",
    "    (train_df['hdl_cholesterol'] < 50).astype(int)\n",
    ")\n",
    "\n",
    "waist_high = np.where(\n",
    "    train_df['gender'] == 'Male',\n",
    "    (train_df['waist_to_hip_ratio'] > 0.9).astype(int),\n",
    "    (train_df['waist_to_hip_ratio'] > 0.85).astype(int)\n",
    ")\n",
    "\n",
    "train_df['metabolic_risk_score'] = (\n",
    "    (train_df['bmi'] >= 30).astype(int) +\n",
    "    (train_df['triglycerides'] >= 150).astype(int) +\n",
    "    hdl_low +\n",
    "    (train_df['systolic_bp'] >= 130).astype(int) +\n",
    "    waist_high\n",
    ").clip(0, 5).astype('category')\n",
    "\n",
    "\n",
    "# Continuous / interaction features\n",
    "test_df['triglycerides_to_hdl'] = test_df['triglycerides'] / test_df['hdl_cholesterol']\n",
    "test_df['non_hdl_cholesterol']  = test_df['cholesterol_total'] - test_df['hdl_cholesterol']\n",
    "test_df['bmi_waist_interaction'] = test_df['bmi'] * test_df['waist_to_hip_ratio']\n",
    "test_df['age_family_interaction'] = test_df['age'] * test_df['family_history_diabetes']\n",
    "\n",
    "# Binary obese flag\n",
    "test_df['obese'] = (test_df['bmi'] >= 30).astype('category')\n",
    "\n",
    "# Gender-specific thresholds\n",
    "hdl_low = np.where(\n",
    "    test_df['gender'] == 'Male',\n",
    "    (test_df['hdl_cholesterol'] < 40).astype(int),\n",
    "    (test_df['hdl_cholesterol'] < 50).astype(int)\n",
    ")\n",
    "\n",
    "waist_high = np.where(\n",
    "    test_df['gender'] == 'Male',\n",
    "    (test_df['waist_to_hip_ratio'] > 0.9).astype(int),\n",
    "    (test_df['waist_to_hip_ratio'] > 0.85).astype(int)\n",
    ")\n",
    "\n",
    "# Metabolic risk score (0–5)\n",
    "test_df['metabolic_risk_score'] = (\n",
    "    (test_df['bmi'] >= 30).astype(int) +\n",
    "    (test_df['triglycerides'] >= 150).astype(int) +\n",
    "    hdl_low +\n",
    "    (test_df['systolic_bp'] >= 130).astype(int) +\n",
    "    waist_high\n",
    ").clip(0, 5).astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55df63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.02,           # slower → much less overfit\n",
    "    'num_leaves': 32,                # reduced\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 50,         # increased\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1.0,\n",
    "    'verbosity': -1,\n",
    "    'seed': 42,\n",
    "    'n_jobs': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd286dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = train_df[\"ethnicity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45175fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "oof_preds = np.zeros(len(X))\n",
    "test_preds = np.zeros(len(X_test))\n",
    "cv_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea926a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_idx, valid_idx) in enumerate(gkf.split(X, y, groups=groups)):\n",
    "    print(f\"\\n=== Fold {fold + 1} ===\")\n",
    "\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_cols.to_list())\n",
    "    lgb_valid = lgb.Dataset(X_valid, label=y_valid, categorical_feature=cat_cols.to_list())\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        valid_names=['train', 'valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100),\n",
    "            lgb.log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    oof_preds[valid_idx] = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    test_preds += model.predict(X_test, num_iteration=model.best_iteration) / n_splits\n",
    "\n",
    "    fold_auc = roc_auc_score(y_valid, oof_preds[valid_idx])\n",
    "    cv_scores.append(fold_auc)\n",
    "    print(f\"Fold {fold + 1} AUC: {fold_auc:.6f}\")\n",
    "\n",
    "print(\"\\nCV AUC:\", np.mean(cv_scores), \"±\", np.std(cv_scores))\n",
    "print(\"OOF AUC:\", roc_auc_score(y, oof_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41925437",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_iterations = int(np.mean([model.best_iteration for model in [model]]))  # just one model per fold, but works\n",
    "# Better: use the rounded average of all folds' best iterations\n",
    "best_iters = [int(model.best_iteration * 1.05) for model in [model]]  # slight buffer\n",
    "final_iterations = int(np.mean([m.best_iteration for m in [model]]) * 1.05)\n",
    "\n",
    "lgb_full = lgb.Dataset(X, label=y, categorical_feature=cat_cols.tolist())\n",
    "\n",
    "final_model = lgb.train(\n",
    "    params,\n",
    "    lgb_full,\n",
    "    num_boost_round=final_iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c1c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test predictions (just to be safe)\n",
    "final_test_preds = final_model.predict(X_test)\n",
    "\n",
    "# Use the CV-averaged predictions as final submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'diagnosed_diabetes': test_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e76cdca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_trial04.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc17a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
