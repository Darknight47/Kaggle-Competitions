{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8865aa5d",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0aceacda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Farhad\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8a5fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c7cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the target feature is of type float\n",
    "train_df['diagnosed_diabetes'] = train_df['diagnosed_diabetes'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c6d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40646cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate', 'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol', 'triglycerides', 'family_history_diabetes', 'hypertension_history', 'cardiovascular_history']\n",
      "Categorical columns: ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', 'employment_status']\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [col for col in numeric_cols if col != 'diagnosed_diabetes']\n",
    "categorical_cols = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e0cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features most correlated with target:\n",
      "diagnosed_diabetes                    1.000000\n",
      "family_history_diabetes               0.211064\n",
      "physical_activity_minutes_per_week    0.169789\n",
      "age                                   0.161162\n",
      "systolic_bp                           0.107132\n",
      "Name: diagnosed_diabetes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# This is a light automated heuristic:\n",
    "# Any feature that perfectly predicts the target (corr == ±1) is suspicious.\n",
    "corr_matrix = train_df[numeric_cols + ['diagnosed_diabetes']].corr()\n",
    "leakage_suspects = corr_matrix['diagnosed_diabetes'].abs().sort_values(ascending=False)\n",
    "print(\"Features most correlated with target:\")\n",
    "print(leakage_suspects.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f57c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encoding for NOMINAL (unordered) categorical features\n",
    "# Nominal (unordered) categories → One-Hot Encoding\n",
    "nominal_cols = ['gender', 'ethnicity', 'employment_status']\n",
    "ordinal_cols = ['education_level', 'income_level', 'smoking_status']\n",
    "\n",
    "# Define the order for ordinal features\n",
    "education_order = [\"No formal\", \"Highschool\", \"Graduate\", \"Postgraduate\"]  \n",
    "income_order    = [\"Low\", \"Lower-Middle\", \"Middle\", \"Upper-Middle\", \"High\"]\n",
    "smoking_order   = [\"Never\", \"Current\", \"Former\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d21b1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal -> OneHot (binary indicators). Creates a new column for each category.\n",
    "nominal_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "# Ordinal -> integer encoding with defined order. Assigns integer values based on order.\n",
    "ordinal_transformer = OrdinalEncoder(\n",
    "    categories=[education_order, income_order, smoking_order],\n",
    "    dtype=int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2a71c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"nominal\", nominal_transformer, nominal_cols),\n",
    "        (\"ordinal\", ordinal_transformer, ordinal_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\" # keeps continuous columns as is. Numeric columns (passthrough) → converted to NumPy array\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c878d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost baseline model\n",
    "# -----------------------------------------------------\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,        # number of trees (moderate baseline)\n",
    "    max_depth=6,            # tree depth: controls model complexity\n",
    "    learning_rate=0.05,     # smaller LR = more stable trees\n",
    "    subsample=0.8,          # row sampling -> reduces overfitting\n",
    "    colsample_bytree=0.8,   # feature sampling -> reduces overfitting\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",      # built-in AUC metric (matches Kaggle)\n",
    "    random_state=42,\n",
    "    n_jobs=-1               # use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36b3b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline: preprocessing + model\n",
    "# -----------------------------------------------------\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),   # from Step 2\n",
    "        (\"model\", xgb_model)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c60a1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=['diagnosed_diabetes'])\n",
    "y = train_df['diagnosed_diabetes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation: Stratified K-Fold CV\n",
    "# -----------------------------------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "auc_scorer = make_scorer(roc_auc_score, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c51c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC scores per fold: [0.72346788 0.72079512 0.7222085  0.7231096  0.72232386]\n",
      "Mean AUC: 0.722380991301365\n",
      "Std deviation: 0.0009230605429321103\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using cross-validation (AUC)\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# Evaluation model\n",
    "cv_scores = cross_val_score(\n",
    "    model_pipeline,\n",
    "    X,\n",
    "    y,\n",
    "    cv=cv,\n",
    "    scoring=auc_scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"AUC scores per fold:\", cv_scores)\n",
    "print(\"Mean AUC:\", cv_scores.mean())\n",
    "print(\"Std deviation:\", cv_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b30af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on full training data\n",
    "# BaseLine Model\n",
    "model_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2da0b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8969e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test_df['id']\n",
    "test_df = test_df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03140dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Apply the same exact encoders\n",
    "# Step 2: Align the columns\n",
    "# Step 3: Produce the exact same feature space\n",
    "# Step 4: Feed into XGBoost correctly\n",
    "# Step 5: Output probabilities\n",
    "test_proba = model_pipeline.predict_proba(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "479c7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "xgb_submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'diagnosed_diabetes': test_proba[:, 1]\n",
    "})\n",
    "xgb_submission.to_csv('xgb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ced5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 5.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 5.0),\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"use_label_encoder\": False,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    \n",
    "    trial_model = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"xgb\", XGBClassifier(**params))\n",
    "    ])\n",
    "    \n",
    "   \n",
    "    groups = train_df['gender']  # your grouping variable\n",
    "    cv = GroupKFold(n_splits=3)\n",
    "\n",
    "    # then use in cross_val_score\n",
    "    scores = cross_val_score(\n",
    "        trial_model, X, y,\n",
    "        cv=cv.split(X, y, groups=train_df['gender']),\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "        \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4aee2b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-08 11:30:40,337] A new study created in memory with name: no-name-17d0d7c1-41ff-4185-9c86-f7fde65190a9\n"
     ]
    }
   ],
   "source": [
    "# Create Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fcf5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final model with tuned params\n",
    "best_params = study.best_params\n",
    "final_model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"xgb\", XGBClassifier(\n",
    "        **best_params,\n",
    "        eval_metric=\"auc\",\n",
    "        use_label_encoder=False,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train on all training data\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a57177af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep test IDs\n",
    "test_df = pd.read_csv(\"dataset/test.csv\")\n",
    "test_ids = test_df['id']\n",
    "test_features = test_df.drop(columns=['id'])\n",
    "\n",
    "# Predict probabilities\n",
    "test_proba = final_model.predict_proba(test_features)[:, 1]\n",
    "\n",
    "# Build submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_ids,\n",
    "    \"diagnosed_diabetes\": test_proba\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv(\"xgb_optuna_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
